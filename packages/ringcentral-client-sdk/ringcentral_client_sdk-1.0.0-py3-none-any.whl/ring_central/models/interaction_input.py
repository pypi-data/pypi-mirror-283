# This file was generated by liblab | https://liblab.com/

from __future__ import annotations
from enum import Enum
from typing import List
from .utils.json_map import JsonMap
from .base import BaseModel
from .insights_enum import InsightsEnum
from .speech_context_phrases_input import SpeechContextPhrasesInput


class InteractionInputEncoding(Enum):
    """An enumeration representing different categories.

    :cvar MPEG: "Mpeg"
    :vartype MPEG: str
    :cvar MP4: "Mp4"
    :vartype MP4: str
    :cvar WAV: "Wav"
    :vartype WAV: str
    :cvar WEBM: "Webm"
    :vartype WEBM: str
    :cvar WEBP: "Webp"
    :vartype WEBP: str
    :cvar AAC: "Aac"
    :vartype AAC: str
    :cvar AVI: "Avi"
    :vartype AVI: str
    :cvar OGG: "Ogg"
    :vartype OGG: str
    """

    MPEG = "Mpeg"
    MP4 = "Mp4"
    WAV = "Wav"
    WEBM = "Webm"
    WEBP = "Webp"
    AAC = "Aac"
    AVI = "Avi"
    OGG = "Ogg"

    def list():
        """Lists all category values.

        :return: A list of all category values.
        :rtype: list
        """
        return list(
            map(lambda x: x.value, InteractionInputEncoding._member_map_.values())
        )


class InteractionInputAudioType(Enum):
    """An enumeration representing different categories.

    :cvar CALLCENTER: "CallCenter"
    :vartype CALLCENTER: str
    :cvar MEETING: "Meeting"
    :vartype MEETING: str
    :cvar EARNINGSCALLS: "EarningsCalls"
    :vartype EARNINGSCALLS: str
    :cvar INTERVIEW: "Interview"
    :vartype INTERVIEW: str
    :cvar PRESSCONFERENCE: "PressConference"
    :vartype PRESSCONFERENCE: str
    :cvar VOICEMAIL: "Voicemail"
    :vartype VOICEMAIL: str
    """

    CALLCENTER = "CallCenter"
    MEETING = "Meeting"
    EARNINGSCALLS = "EarningsCalls"
    INTERVIEW = "Interview"
    PRESSCONFERENCE = "PressConference"
    VOICEMAIL = "Voicemail"

    def list():
        """Lists all category values.

        :return: A list of all category values.
        :rtype: list
        """
        return list(
            map(lambda x: x.value, InteractionInputAudioType._member_map_.values())
        )


@JsonMap(
    {
        "content_uri": "contentUri",
        "language_code": "languageCode",
        "audio_type": "audioType",
        "separate_speaker_per_channel": "separateSpeakerPerChannel",
        "speaker_count": "speakerCount",
        "speaker_ids": "speakerIds",
        "enable_voice_activity_detection": "enableVoiceActivityDetection",
        "speech_contexts": "speechContexts",
    }
)
class InteractionInput(BaseModel):
    """InteractionInput

    :param content_uri: Publicly facing uri, defaults to None
    :type content_uri: str, optional
    :param encoding: The encoding of the original audio, defaults to None
    :type encoding: InteractionInputEncoding, optional
    :param language_code: Language spoken in the audio file., defaults to None
    :type language_code: str, optional
    :param source: Source of the audio file eg: Phone, RingCentral, GoogleMeet, Zoom etc, defaults to None
    :type source: str, optional
    :param audio_type: Type of the audio, defaults to None
    :type audio_type: InteractionInputAudioType, optional
    :param separate_speaker_per_channel: Set to True if the input audio is multi-channel and each channel has a separate speaker., defaults to None
    :type separate_speaker_per_channel: bool, optional
    :param speaker_count: Number of speakers in the file, omit parameter if unknown, defaults to None
    :type speaker_count: int, optional
    :param speaker_ids: Optional set of speakers to be identified from the call., defaults to None
    :type speaker_ids: List[str], optional
    :param enable_voice_activity_detection: Apply voice activity detection., defaults to None
    :type enable_voice_activity_detection: bool, optional
    :param insights: insights, defaults to None
    :type insights: List[InsightsEnum], optional
    :param speech_contexts: Indicates the words/phrases that will be used for boosting the transcript. This can help to boost accuracy for cases like Person Names, Company names etc., defaults to None
    :type speech_contexts: List[SpeechContextPhrasesInput], optional
    """

    def __init__(
        self,
        content_uri: str = None,
        encoding: InteractionInputEncoding = None,
        language_code: str = None,
        source: str = None,
        audio_type: InteractionInputAudioType = None,
        separate_speaker_per_channel: bool = None,
        speaker_count: int = None,
        speaker_ids: List[str] = None,
        enable_voice_activity_detection: bool = None,
        insights: List[InsightsEnum] = None,
        speech_contexts: List[SpeechContextPhrasesInput] = None,
    ):
        if content_uri is not None:
            self.content_uri = content_uri
        if encoding is not None:
            self.encoding = self._enum_matching(
                encoding, InteractionInputEncoding.list(), "encoding"
            )
        if language_code is not None:
            self.language_code = language_code
        if source is not None:
            self.source = source
        if audio_type is not None:
            self.audio_type = self._enum_matching(
                audio_type, InteractionInputAudioType.list(), "audio_type"
            )
        if separate_speaker_per_channel is not None:
            self.separate_speaker_per_channel = separate_speaker_per_channel
        if speaker_count is not None:
            self.speaker_count = speaker_count
        if speaker_ids is not None:
            self.speaker_ids = speaker_ids
        if enable_voice_activity_detection is not None:
            self.enable_voice_activity_detection = enable_voice_activity_detection
        if insights is not None:
            self.insights = self._define_list(insights, InsightsEnum)
        if speech_contexts is not None:
            self.speech_contexts = self._define_list(
                speech_contexts, SpeechContextPhrasesInput
            )
