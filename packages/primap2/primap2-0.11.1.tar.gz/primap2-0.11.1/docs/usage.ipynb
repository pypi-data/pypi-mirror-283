{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# General Usage\n",
    "\n",
    "Because PRIMAP2 builds on xarray, all xarray functionality is available\n",
    "right away.\n",
    "Additional functionality is provided in the ``primap2`` package and\n",
    "in the ``pr`` namespace on xarray objects.\n",
    "In this section, we will present examples of general PRIMAP2 usage,\n",
    "which are likely to be helpful in any context.\n",
    "More specialized functionality for specific tasks is presented in the\n",
    "next section.\n",
    "\n",
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import primap2  # injects the \"pr\" namespace into xarray"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# set up logging for the docs - don't show debug messages\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading Datafiles\n",
    "\n",
    "### Loading from netcdf files\n",
    "\n",
    "The native storage format of PRIMAP2 are netcdf5 files, and datasets\n",
    "can be written to and loaded from netcdf5 files using PRIMAP2 functions.\n",
    "We will load the \"minimal\" and \"opulent\" Datasets from the data format section:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds_min = primap2.open_dataset(\"minimal_ds.nc\")\n",
    "ds = primap2.open_dataset(\"opulent_ds.nc\")\n",
    "\n",
    "ds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Accessing metadata\n",
    "\n",
    "Metadata is stored in the `attrs` of Datasets, and you can of course\n",
    "access it directly there.\n",
    "Additionally, you can access the PRIMAP2 metadata directly under\n",
    "the `.pr` namespace, which has the advantage that autocompletion\n",
    "works in ipython and IDEs and typos will be caught immediately."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds.attrs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds.pr.title"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds.pr.title = \"Another title\"\n",
    "ds.pr.title"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Selecting data\n",
    "\n",
    "Data can be selected using the\n",
    "[xarray indexing methods](https://xarray.pydata.org/en/stable/indexing.html),\n",
    "but PRIMAP2 also provides own versions of some of xarray's selection methods\n",
    "which work using the dimension names without the category set.\n",
    "\n",
    "### Getitem\n",
    "\n",
    "The following selections both select the same:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds[\"area (ISO3)\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds.pr[\"area\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The loc Indexer\n",
    "\n",
    "Similarly, a version of the `loc` indexer is provided which works with the\n",
    "bare dimension names:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ds.pr.loc[{\"time\": slice(\"2002\", \"2005\"), \"animal\": \"cow\"}]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It also works on DataArrays:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da = ds[\"CO2\"]\n",
    "\n",
    "da_subset = da.pr.loc[\n",
    "    {\n",
    "        \"time\": slice(\"2002\", \"2005\"),\n",
    "        \"animal\": \"cow\",\n",
    "        \"category\": \"0\",\n",
    "        \"area\": \"COL\",\n",
    "    }\n",
    "]\n",
    "da_subset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Negative Selections\n",
    "\n",
    "Using the primap2 `loc` indexer, you can also use negative selections to select\n",
    "everything but the specified value or values along a dimension: "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from primap2 import Not\n",
    "\n",
    "ds.pr.loc[{\"time\": slice(\"2002\", \"2005\"), \"animal\": Not(\"cow\")}]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting data\n",
    "\n",
    "PRIMAP2 provides a unified API to introduce new data values, fill missing information,\n",
    "and overwrite existing information:\n",
    "the [da.pr.set](https://primap2.readthedocs.io/en/main/generated/xarray.DataArray.pr.set.html)\n",
    "function and its sibling\n",
    "[ds.pr.set](https://primap2.readthedocs.io/en/main/generated/xarray.Dataset.pr.set.html).\n",
    "\n",
    "The basic signature of the `set` functions is `set(dimension, keys, values)`, and it\n",
    "returns the changed object without changing the original one.\n",
    "Use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da = ds_min[\"CO2\"].loc[{\"time\": slice(\"2000\", \"2005\")}]\n",
    "da"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "from primap2 import ureg\n",
    "\n",
    "modified = da.pr.set(\n",
    "    \"area\", \"CUB\", np.linspace(0, 20, 6) * ureg(\"Gg CO2 / year\")\n",
    ")\n",
    "modified"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, existing non-NaN values are not overwritten:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "try:\n",
    "    da.pr.set(\"area\", \"COL\", np.linspace(0, 20, 6) * ureg(\"Gg CO2 / year\"))\n",
    "except ValueError as err:\n",
    "    print(err)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can overwrite existing values by specifying `existing=\"overwrite\"`\n",
    "to overwrite all values or `existing=\"fillna\"` to overwrite only NaNs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da.pr.set(\n",
    "    \"area\",\n",
    "    \"COL\",\n",
    "    np.linspace(0, 20, 6) * ureg(\"Gg CO2 / year\"),\n",
    "    existing=\"overwrite\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, the `set()` function extends the specified dimension automatically to\n",
    "accommodate new values if not all key values are in the specified dimension yet.\n",
    "You can change this by specifying `new=\"error\"`, which will raise a KeyError if any of\n",
    "the keys is not found:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "try:\n",
    "    da.pr.set(\n",
    "        \"area\",\n",
    "        [\"COL\", \"CUB\"],\n",
    "        np.linspace(0, 20, 6) * ureg(\"Gg CO2 / year\"),\n",
    "        existing=\"overwrite\",\n",
    "        new=\"error\",\n",
    "    )\n",
    "except KeyError as err:\n",
    "    print(err)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In particular, the `set()` functions can also be used with xarray's arithmetic\n",
    "functions to derive values from existing data and store the result in the Dataset.\n",
    "As an example, we will derive better values for category 0 by adding all\n",
    "its subcategories and store the result.\n",
    "\n",
    "First, let's see the current data for a small subset of the data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sel = {\n",
    "    \"area\": \"COL\",\n",
    "    \"category\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],\n",
    "    \"animal\": \"cow\",\n",
    "    \"product\": \"milk\",\n",
    "    \"scenario\": \"highpop\",\n",
    "    \"source\": \"RAND2020\",\n",
    "}\n",
    "subset = ds.pr.loc[sel].squeeze()\n",
    "\n",
    "# TODO: currently, plotting with units still emits a warning\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    subset[\"CO2\"].plot.line(x=\"time\", hue=\"category (IPCC 2006)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While it is hard to see any details in this plot, it is clearly visible\n",
    "that category 0 is not the sum of the other categories (which should not\n",
    "come as a surprise since we generated the data at random).\n",
    "\n",
    "We will now recompute category 0 for the entire dataset using set():"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cat0_new = ds.pr.loc[{\"category\": [\"1\", \"2\", \"3\", \"4\", \"5\"]}].pr.sum(\n",
    "    \"category\"\n",
    ")\n",
    "\n",
    "ds = ds.pr.set(\n",
    "    \"category\",\n",
    "    \"0\",\n",
    "    cat0_new,\n",
    "    existing=\"overwrite\",\n",
    ")\n",
    "\n",
    "# plot a small subset of the result\n",
    "subset = ds.pr.loc[sel].squeeze()\n",
    "# TODO: currently, plotting with units still emits a warning\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    subset[\"CO2\"].plot.line(x=\"time\", hue=\"category (IPCC 2006)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see in the plot, category 0 is now computed from its subcategories.\n",
    "The set() method of Datasets works on all data variables in the dataset which\n",
    "have the corresponding dimension. In this example, the \"population\" variable\n",
    "does not have categories, so it was unchanged."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adding dimensions\n",
    "When adding a dimension to a primap2 dataset one also has to keeps the attrs up to date. Thus the `xr.ds.expand_dims` function does not suffice. The function [ds.pr.expand_dims](https://primap2.readthedocs.io/en/main/generated/xarray.Dataset.pr.expand_dims.html) takes care of the attrs for you. The following example adds a category dimension with coordinate value '0' and terminology 'IPCC2006' to `ds_min` and adds the alias to the attrs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds_dim_added = ds_min.pr.expand_dims(dim='category', coord_value=['0'], terminology='IPCC2006')\n",
    "ds_dim_added"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Unit handling\n",
    "\n",
    "PRIMAP2 uses the [openscm_units](https://openscm-units.readthedocs.io)\n",
    "package based on the [Pint](https://pint.readthedocs.io/) library\n",
    "for handling of units.\n",
    "\n",
    "### CO2 equivalent units and mass units\n",
    "\n",
    "Using global warming potential contexts, it is easy to convert mass units\n",
    "into CO2 equivalents:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from primap2 import ureg  # The unit registry\n",
    "\n",
    "sf6_gwp = ds[\"SF6\"].pr.convert_to_gwp(\n",
    "    gwp_context=\"AR4GWP100\", units=\"Gg CO2 / year\"\n",
    ")\n",
    "# The information about the used GWP context is retained:\n",
    "sf6_gwp.attrs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because the GWP context used for conversion is stored, it is equally easy\n",
    "to convert back to mass units:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sf6 = sf6_gwp.pr.convert_to_mass()\n",
    "sf6.attrs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The stored GWP context can also be used to convert another array using the\n",
    "same context:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ch4_gwp = ds[\"CH4\"].pr.convert_to_gwp_like(sf6_gwp)\n",
    "ch4_gwp.attrs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dropping units\n",
    "\n",
    "Sometimes, it is necessary to drop the units, for example to use\n",
    "arrays as input for external functions which are unit-naive.\n",
    "This can be done safely by first converting to the target unit, then\n",
    "dequantifying the dataset or array:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da_nounits = ds[\"CH4\"].pint.to(\"Mt CH4 / year\").pr.dequantify()\n",
    "da_nounits.attrs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that the units are then stored in the DataArray's `attrs`, and can be\n",
    "restored using the\n",
    "[da.pr.quantify](https://primap2.readthedocs.io/en/main/generated/xarray.DataArray.pr.quantify.html)\n",
    "function.\n",
    "\n",
    "## Descriptive statistics\n",
    "\n",
    "To get an overview about the missing information in a Dataset or DataArray, you\n",
    "can use the `pr.coverage` function. It gives you a summary\n",
    "of the number of non-NaN data points:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "time = pd.date_range(\"2000-01-01\", \"2003-01-01\", freq=\"YS\")\n",
    "area_iso3 = np.array([\"COL\", \"ARG\", \"MEX\"])\n",
    "category_ipcc = np.array([\"1\", \"2\"])\n",
    "coords = [\n",
    "    (\"category (IPCC2006)\", category_ipcc),\n",
    "    (\"area (ISO3)\", area_iso3),\n",
    "    (\"time\", time),\n",
    "]\n",
    "da = xr.DataArray(\n",
    "    data=[\n",
    "        [\n",
    "            [1, 2, 3, 4],\n",
    "            [np.nan, np.nan, np.nan, np.nan],\n",
    "            [1, 2, 3, np.nan],\n",
    "        ],\n",
    "        [\n",
    "            [np.nan, 2, np.nan, 4],\n",
    "            [1, np.nan, 3, np.nan],\n",
    "            [1, np.nan, 3, np.nan],\n",
    "        ],\n",
    "    ],\n",
    "    coords=coords,\n",
    ")\n",
    "\n",
    "da"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da.pr.coverage(\"area\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da.pr.coverage(\"time\", \"area\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For Datasets, you can also specify the \"entity\" as a coordinate to summarize for the\n",
    "data variables:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import primap2.tests\n",
    "\n",
    "ds = primap2.tests.examples.opulent_ds()\n",
    "ds[\"CO2\"].pr.loc[{\"product\": \"milk\"}].pint.magnitude[:] = np.nan\n",
    "\n",
    "ds.pr.coverage(\"product\", \"entity\", \"area\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merging\n",
    "\n",
    "xarray provides different functions to combine Datasets and DataArrays.\n",
    "However, these are not built to combine data which contain duplicates\n",
    "with rounding / processing errors. However, when reading data e.g. from country\n",
    "reports this is often needed as some sectors are included in several tables\n",
    "and might use different numbers of decimals. Thus, PRIMAP2 has added a merge\n",
    "function that can accept data discrepancies not exceeding a given tolerance\n",
    "level. The merging of attributes is handled by xarray and the `combine_attrs`\n",
    "parameter is just passed on to the xarray functions. Default is to `drop_conflicts`.\n",
    "\n",
    "Below an example using the built in `opulent_ds`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from primap2.tests.examples import opulent_ds\n",
    "import xarray as xr\n",
    "\n",
    "op_ds = opulent_ds()\n",
    "# only take part of the countries to have something to actually merge\n",
    "da_start = op_ds[\"CO2\"].pr.loc[{\"area\": [\"ARG\", \"COL\", \"MEX\"]}]\n",
    "# modify some data\n",
    "data_to_modify = op_ds[\"CO2\"].pr.loc[{\"area\": [\"ARG\"]}].pr.sum(\"area\")\n",
    "data_to_modify.data = data_to_modify.data * 1.009\n",
    "da_merge = op_ds[\"CO2\"].pr.set(\n",
    "    \"area\", \"ARG\", data_to_modify, existing=\"overwrite\"\n",
    ")\n",
    "\n",
    "# merge with tolerance such that it will pass\n",
    "da_result = da_start.pr.merge(da_merge, tolerance=0.01)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# merge with lower tolerance such that it will fail\n",
    "try:\n",
    "    # the logged message is very large, only show a small part\n",
    "    logger.disable(\"primap2\")\n",
    "    da_result = da_start.pr.merge(da_merge, tolerance=0.005)\n",
    "except xr.MergeError as err:\n",
    "    err_short = \"\\n\".join(str(err).split(\"\\n\")[0:6])\n",
    "    print(f\"An error occured during merging: {err_short}\")\n",
    "logger.enable(\"primap2\")\n",
    "\n",
    "# you sould also only log a warning and not raise an error\n",
    "# using the error_on_discrepancy=False argument to `merge`"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Aggregation and infilling\n",
    "\n",
    "xarray provides robust functions for aggregation (`sum`) and filling of\n",
    "missing information (`fillna`).\n",
    "PRIMAP2 adds functions which fill or skip missing information based on if the\n",
    "information is missing at all points along certain axes, for example for\n",
    "a whole time series.\n",
    "This makes it possible to, for example, evaluate the sum of sub-categories\n",
    "while ignoring only those categories which are missing completely.\n",
    "It is also possible to ignore NA values (i.e. treating them as 0) in sums using \n",
    "the `skipna` parameter. \n",
    "When using `skipna`, the `min_count` parameter governs how many non-NA vales are \n",
    "needed in a sum for the result to be non-NA. The default value is `skipna=1`. \n",
    "This is helpful if you want to e.g. sum all subsectors and for some countries \n",
    "or gases some of the subsectors have NA values because there is no data. To avoid\n",
    "NA timeseries if a single sector is NA you use `skipna`. In other cases, e.g. when \n",
    "checking if data coverage is complete `skipna` is not used, so any NA value in the \n",
    "source data results in NA in the summed data and is not hidden. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "time = pd.date_range(\"2000-01-01\", \"2003-01-01\", freq=\"YS\")\n",
    "area_iso3 = np.array([\"COL\", \"ARG\", \"MEX\"])\n",
    "coords = [(\"area (ISO3)\", area_iso3), (\"time\", time)]\n",
    "da = xr.DataArray(\n",
    "    data=[\n",
    "        [1, 2, 3, 4],\n",
    "        [np.nan, np.nan, np.nan, np.nan],\n",
    "        [1, 2, 3, np.nan],\n",
    "    ],\n",
    "    coords=coords,\n",
    ")\n",
    "\n",
    "da"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da.pr.sum(dim=\"area\", skipna_evaluation_dims=\"time\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "da.pr.sum(dim=\"area\", skipna=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# compare this to the result of the standard xarray sum:\n",
    "\n",
    "da.sum(dim=\"area (ISO3)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The same functionality is available for filling in missing information:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "da.pr.fill_all_na(\"time\", value=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For lager aggregation tasks, e.g. aggregating several gas baskets from individual gases or aggregating a full category tree from leaves we have the functions [ds.pr.add_aggregates_variables](https://primap2.readthedocs.io/en/main/generated/xarray.Dataset.pr.add_aggregates_variables.html), [ds.pr.add_aggregates_coordinates](https://primap2.readthedocs.io/en/main/generated/xarray.Dataset.pr.add_aggregates_coordinates.html), and [da.pr.add_aggregates_coordinates](https://primap2.readthedocs.io/en/main/generated/xarray.DataArray.pr.add_aggregates_coordinates.html) which are highly configurable, but can also be used in a simplified mode for quick aggregation tasks. In the following we give a few examples. For the full feature set we refer to function descriptions linked above. The functions internally work with `ds/da.pr.merge()` to allow for consistency checks when target timeseries exist. \n",
    "\n",
    " ### ds.pr.add_aggregates_variables\n",
    " \n",
    " This function aggregates data from individual variables to new variables (usually gas baskets). Several variables can be created in one call where the order of definition is the order of creation. Filters can be specified to limit aggregation to certain coordinate values.\n",
    " \n",
    "**Examples**\n",
    "\n",
    "Sum gases in the minimal example dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "summed_ds = ds_min.pr.add_aggregates_variables(\n",
    "    gas_baskets={\n",
    "        \"test (SARGWP100)\": {\n",
    "            \"sources\": [\"CO2\", \"SF6\", \"CH4\"],\n",
    "        },\n",
    "    },\n",
    ")\n",
    "summed_ds[\"test (SARGWP100)\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also use a filter to limit the aggregation to a single country:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_ds = ds_min.pr.add_aggregates_variables(\n",
    "    gas_baskets={\n",
    "        \"test (SARGWP100)\": {\n",
    "            \"sources\": [\"CO2\", \"SF6\", \"CH4\"],\n",
    "            \"filter\": {\"area (ISO3)\": [\"COL\"]},\n",
    "        },\n",
    "    },\n",
    ")\n",
    "filtered_ds[\"test (SARGWP100)\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we recompute an existing timeseries it has to be consistent with the existing data. Here we use the simple mode to specify the aggregation rules."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xarray import MergeError\n",
    "try:\n",
    "    recomputed_ds = filtered_ds.pr.add_aggregates_variables(\n",
    "        gas_baskets={\n",
    "            \"test (SARGWP100)\": [\"CO2\", \"CH4\"],\n",
    "        },\n",
    "    )\n",
    "    recomputed_ds[\"test (SARGWP100)\"]\n",
    "except MergeError as err:\n",
    "    print(err)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "unless we set the tolerance high enough (only possible in the complex mode for the aggregation rules)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recomputed_ds = filtered_ds.pr.add_aggregates_variables(\n",
    "    gas_baskets={\n",
    "        \"test (SARGWP100)\": {\n",
    "            \"sources\": [\"CO2\", \"CH4\"],\n",
    "            \"tolerance\": 1 #  100%\n",
    "        },\n",
    "    },\n",
    ")\n",
    "recomputed_ds[\"test (SARGWP100)\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### ds.pr.add_aggregates_coordinates\n",
    "\n",
    "This function aggregates data from individual coordinate values to new values (e.g. from subcategories to categories). Several values for several coordinates can be created in one call where the order of definition is the order of creation. Filters can be specified to limit aggregation to certain coordinate values, entities or variables. most of the operation is similar to the variable aggregation and thus we keep the examples here shorter. The [da.pr.add_aggregates_coordinates](https://primap2.readthedocs.io/en/main/generated/xarray.DataArray.pr.add_aggregates_coordinates.html) function uses the same syntax.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "Sum countries in the minimal example dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_ds = ds_min.pr.add_aggregates_coordinates(\n",
    "    agg_info={\n",
    "        \"area (ISO3)\": {\n",
    "            \"all\": {\n",
    "                \"sources\": [\"COL\", \"ARG\", \"MEX\", \"BOL\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "test_ds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The difference between the `entity` and `variable` filters is that `'entity': ['SF6']` will match both variables `'SF6'` and `'SF6 (SARGWP100)'` (as both variables are for the entity `'SF6'`) while `'variable': ['SF6']` will match only the variable `'SF6'`."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
