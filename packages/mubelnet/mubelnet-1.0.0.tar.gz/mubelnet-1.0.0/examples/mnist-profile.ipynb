{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " # Add end-to-end package to path.\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('../src').absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 14:41:23.207981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Run the following before any XLA modules such as JAX:\n",
    "import chex\n",
    "\n",
    "chex.set_n_cpu_devices(2)\n",
    "\n",
    "# Import the remaining JAX related \n",
    "from gabenet.mcmc import sample_markov_chain\n",
    "from gabenet.nets import PoissonGammaBelieve\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "X_train = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Pseudo-random number generator sequence.\n",
    "key_seq = hk.PRNGSequence(42)\n",
    "\n",
    "m_samples, n_features = X_train.shape\n",
    "\n",
    "def build_gamma_belief_net():\n",
    "    \"\"\"A two-layer decoder network.\"\"\"\n",
    "    n_hidden_units = (10, )\n",
    "    return PoissonGammaBelieve(n_hidden_units, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.transform_with_state\n",
    "def kernel():\n",
    "    \"\"\"Advances the Markov chain by one step.\"\"\"\n",
    "    model = build_gamma_belief_net()\n",
    "    model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.transform_with_state\n",
    "def forward():\n",
    "    \"\"\"Initialise Markov chain using forward samples.\"\"\"\n",
    "    model = build_gamma_belief_net()\n",
    "    return model.forward(m_samples)\n",
    "\n",
    "param_init, state_init = forward.init(next(key_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with jax.profiler.trace(\"/tmp/forward-trace\"):\n",
    "#     X, _ = forward.apply(param_init, state_init, next(key_seq))\n",
    "#     X.block_until_ready()\n",
    "#     # state_init['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4.0652275e+00, 4.4300509e-04, 6.0318822e-01, 2.3464619e-03,\n",
       "       1.1366474e-03, 1.5800984e+00, 5.6379624e-05, 4.6082416e+00,\n",
       "       2.7244008e-04, 1.8254912e-01], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, state = kernel.apply(param_init, state_init, next(key_seq))\n",
    "state['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.profiler.trace(\"/tmp/backward-trace\"):\n",
    "    _, state = kernel.apply(param_init, state_init, next(key_seq))\n",
    "    state['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4.2245402e+00, 2.2497942e-04, 5.9250891e-01, 4.5619719e-03,\n",
       "       1.5383102e-03, 1.5621212e+00, 8.0437101e-05, 4.6301651e+00,\n",
       "       6.8614125e-04, 1.7477462e-01], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_jit = jax.jit(kernel.apply)\n",
    "# Warm-up.\n",
    "_, state = kernel_jit(param_init, state_init, next(key_seq))\n",
    "state['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.9794190e+00, 9.3176265e-12, 6.1930192e-01, 3.2035506e-03,\n",
       "       5.4359541e-04, 1.5460705e+00, 9.8756704e-05, 4.6776247e+00,\n",
       "       2.2216747e-04, 1.8224584e-01], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, state = kernel_jit(param_init, state_init, next(key_seq))\n",
    "state['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jax.profiler.trace(\"/tmp/backward-compiled-trace\"):\n",
    "    _, state = kernel_jit(param_init, state_init, next(key_seq))\n",
    "    state['poisson_gamma_believe/~/cap_layer']['r'].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
