Metadata-Version: 2.1
Name: lmnr
Version: 0.2.3.1
Summary: Python SDK for Laminar AI
License: Apache-2.0
Author: lmnr.ai
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: black (>=24.4.2,<25.0.0)
Requires-Dist: click (>=8.1.7,<9.0.0)
Requires-Dist: cookiecutter (>=2.6.0,<3.0.0)
Requires-Dist: pydantic (>=2.7.4,<3.0.0)
Requires-Dist: python-dotenv (>=1.0.1,<2.0.0)
Requires-Dist: requests (>=2.32.3,<3.0.0)
Requires-Dist: urllib3 (==1.26.6)
Requires-Dist: websockets (>=12.0,<13.0)
Description-Content-Type: text/markdown

# Python SDK for Laminar AI

Example use:

```python
from lmnr import Laminar

l = Laminar('<YOUR_PROJECT_API_KEY>')
result = l.run(
    endpoint = 'my_endpoint_name',
    inputs = {'input_node_name': 'some_value'},
    env = {'OPENAI_API_KEY': 'sk-some-key'},
    metadata = {'session_id': 'your_custom_session_id'}
)
```

Resulting in:

```python
>>> result
EndpointRunResponse(outputs={'output': {'value': [ChatMessage(role='user', content='hello')]}}, run_id='53b012d5-5759-48a6-a9c5-0011610e3669')
```

## CLI for code generation

### Basic usage

```
lmnr pull <pipeline_name> <pipeline_version_name> --project-api-key <PROJECT_API_KEY>
```

Read more [here](https://docs.lmnr.ai/api-reference/introduction#authentication) on how to get `PROJECT_API_KEY`.

To import your pipeline
```python
# submodule with the name of your pipeline will be generated in lmnr_engine.pipelines
from lmnr_engine.pipelines.my_custom_pipeline import MyCustomPipeline


pipeline = MyCustomPipeline()
res = pipeline.run(
    inputs={
        "instruction": "Write me a short linked post about dev tool for LLM developers which they'll love"
    },
    env={
        "OPENAI_API_KEY": <OPENAI_API_KEY>,
    }
)
print(f"RESULT:\n{res}")
```

### Current functionality
- Supports graph generation for graphs with Input, Output, and LLM nodes only
- For LLM nodes, it only supports OpenAI and Anthropic models and doesn't support structured output

